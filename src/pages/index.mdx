---
layout: ../layouts/Layout.astro
title: Surfacing Variations to Calibrate Perceived Reliability of MLLM-Generated Image Descriptions
authors:
  - name: Meng Chen
    url: https://meng-chen.com
    institution: UT Austin
  - name: Akhil Iyer
    institution: UT Austin
  - name: Amy Pavel
    url: https://amypavel.com
    institution: UC Berkeley
conference: ASSETS 2025
links:
  - name: Paper
    url: https://dl.acm.org/doi/full/10.1145/3663547.3746393
    icon: ri:file-pdf-2-line
  - name: arXiv
    url: https://arxiv.org/abs/2507.15692
    icon: academicons:arxiv
  - name: Code
    url: https://github.com/Casardo-Chen/surface-mllm-variations
    icon: ri:github-line
  - name: System
    url: #
    icon: ri:link

# The color theme of the page. Defaults to "device" (the preference set in the user's brower or operating system). Setting this to "light" or "dark" will override the user's preference. This is useful if your figures only look good in one theme.
theme: device

# This is the icon that appears in the user's browser tab. To customize, change the favicon.svg file in /public/, or add your own file to /public/ and change the filename here.
favicon: favicon.svg

# These keys are optional. If a link to your project page is in a Google search result, text message, or social media post, it will often appear as a "link preview card" based on its title, description, favicon, and thumbnail. After you publish your page, you can double check that these previews look right using [this tool](https://linkpreview.xyz/)
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
thumbnail: screenshot-light.png
---

import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Picture from "../components/Picture.astro";
import ModelViewer from "../components/ModelViewer.astro"
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { Comparison } from "../components/Comparison.tsx";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import dogsDiffc from "../assets/dogs-diffc.png"
import dogsTrue from "../assets/dogs-true.png"
import teaser from "../assets/teaser.png"

import Table from "../components/Table.astro";
export const components = { table: Table }

<Figure>
  <Picture slot="figure" src={teaser} alt="System Pipeline" invertInDarkMode />
  <Fragment slot="caption"> <b>(A)</b> Input image and prompt. <b>(B)</b> Raw image descriptions from 3 MLLMs (GPT-4o, Gemini-1.5-Pro, Claude-3.7-Sonnet).
<b>(C)</b> <i>Variation-Aware Description</i> aggregates all model outputs into a hierarchical markdown. Major variations are highlighted
in indigo. <b>(D)</b> <i>Variation summary</i> further surfaces key agreements, disagreements, and unique mentions across models.</Fragment>
</Figure>

<HighlightedSection>

## Abstract

Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users’ ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado’s path to posting an image on social media.

</HighlightedSection>

## Design Space

| **Dimension**              | **Alternatives** | | | |
|-----------------------------|--------------------|--------------------|--------------------|--------------------|
| **Elicitation of Variants** | `Trials`             |  `Prompts`           |  `Models`            | `Images`             |
| **Comparison Support**      | List               | Variation-aware description | Variation Summary |            |
| **Comparison Granularity**  | Words              | Atomic facts       | Sentences        | Responses            |
| **Support Indicator**       | None               | Percentage         | Language         | Source               |
| **Provenance Indicator**    | None               | Trials             | Prompts            | Models             |
| **Modality**                | Text               | Sound              | Visualization      | Haptics            |

## Uncertainty Presentation

| **None** | **Language** | **Percentage** | **Source** |
|-----------|--------------|----------------|-------------|
| There are two <span style="background-color:#ccffcc;">white chairs</span> on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble or glass or wood</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books and a television</span>. | There are two <span style="background-color:#ccffcc;">white (well-supported)</span> chairs on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble (moderately supported) or glass (poorly supported) or wood (very little support)</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books (moderately supported) and a television (moderately supported)</span>. | There are two <span style="background-color:#ccffcc;">white (100%)</span> chairs on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble (56%) or glass (33%) or wood (11%)</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books (33%) and a television (33%)</span>. | There are two <span style="background-color:#ccffcc;">white (3 of 3 GPT, 3 of 3 Gemini, 3 of 3 Claude)</span> chairs on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble (3 of 3 GPT, 2 of 3 Gemini) or glass (3 of 3 Claude) or wood (1 of 3 Gemini)</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books (3 of 3 GPT) and a television (3 of 3 Gemini)</span>. |

Variation-aware description without support indicator and with three variant support indicators (Language, Percentage, Source). Agreements (top, <span style="background-color:#ccffcc;">green</span>), disagreements (middle, <span style="background-color:#ffcccc;">red</span>), and unique mentions (bottom, <span style="background-color:#cce5ff;">blue</span>) are highlighted.


## Results

To be updated.

<Figure>
  <Picture slot="figure" src="../assets/results_bars.pdf" alt="Results" invertInDarkMode />
  <Fragment slot="caption"> Left: average identified unreliable claims reported by participants overall and in each image category. Right: average perceived reliability rating (1 = not reliable at all, 7 = most reliable) overall and in each image category. Error bars represent a 95\% confidence interval. We applied the Friedman test followed by pairwise Wilcoxon signed-rank tests with Bonferroni correction. Significance is marked as * $p < 0.05$, ** $p < 0.01$, and *** $p < 0.001$..</Fragment>
</Figure>




## BibTeX 

```bibtex
@inproceedings{10.1145/3663547.3746393,
  author = {Chen, Meng and Iyer, Akhil and Pavel, Amy},
  title = {Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions},
  year = {2025},
  isbn = {9798400706769},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3663547.3746393},
  doi = {10.1145/3663547.3746393},
  abstract = {Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users’ ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado’s path to posting an image on social media.},
  booktitle = {Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility},
  articleno = {66},
  numpages = {17},
  keywords = {Accessibility, Image Descriptions, Multimodal Large Language Models, Variations, AI Errors, Trust},
  location = {Denver, CO, USA },
  series = {ASSETS '25}
}
```