---
layout: ../layouts/Layout.astro
title: Surfacing Variations to Calibrate Perceived Reliability of MLLM-Generated Image Descriptions
authors:
  - name: Meng Chen
    url: https://meng-chen.com
    institution: UT Austin
  - name: Akhil Iyer
    institution: UT Austin
  - name: Amy Pavel
    url: https://amypavel.com
    institution: UC Berkeley
conference: ASSETS 2025
links:
  - name: Paper
    url: https://dl.acm.org/doi/full/10.1145/3663547.3746393
    icon: ri:file-pdf-2-line
  - name: arXiv
    url: https://arxiv.org/abs/2507.15692
    icon: academicons:arxiv
  - name: Code
    url: https://github.com/Casardo-Chen/surface-mllm-variations
    icon: ri:github-line
  - name: System
    url: https://surface-mllm-variations.github.io/
    icon: ri:link

# The color theme of the page. Defaults to "device" (the preference set in the user's brower or operating system). Setting this to "light" or "dark" will override the user's preference. This is useful if your figures only look good in one theme.
theme: device

# This is the icon that appears in the user's browser tab. To customize, change the favicon.svg file in /public/, or add your own file to /public/ and change the filename here.
favicon: favicon.svg

# These keys are optional. If a link to your project page is in a Google search result, text message, or social media post, it will often appear as a "link preview card" based on its title, description, favicon, and thumbnail. After you publish your page, you can double check that these previews look right using [this tool](https://linkpreview.xyz/)
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
thumbnail: screenshot-light.png
---

import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Picture from "../components/Picture.astro";
import ModelViewer from "../components/ModelViewer.astro"
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { Comparison } from "../components/Comparison.tsx";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import dogsDiffc from "../assets/dogs-diffc.png"
import dogsTrue from "../assets/dogs-true.png"
import teaser from "../assets/teaser.png"

import Table from "../components/Table.astro";
export const components = { table: Table }

<Figure>
  <Picture slot="figure" src={teaser} alt="Diagram of the transformer deep learning architecture." invertInDarkMode />
  <Fragment slot="caption"> <b>(A)</b> Input image and prompt. <b>(B)</b> Raw image descriptions from 3 MLLMs (GPT-4o, Gemini-1.5-Pro, Claude-3.7-Sonnet).
<b>(C)</b> <i>Variation-Aware Description</i> aggregates all model outputs into a hierarchical markdown. Major variations are highlighted
in indigo. <b>(D)</b> <i>Variation summary</i> further surfaces key agreements, disagreements, and unique mentions across models.</Fragment>
</Figure>

<HighlightedSection>

## Abstract

Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users’ ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado’s path to posting an image on social media.

</HighlightedSection>

## Design Space

| **Dimension**              | **Alternatives** | | | |
|-----------------------------|--------------------|--------------------|--------------------|--------------------|
| **Elicitation of Variants** | `Trials`             |  `Prompts`           |  `Models`            | `Images`             |
| **Comparison Support**      | List               | Variation-aware description | Variation Summary |            |
| **Comparison Granularity**  | Words              | Atomic facts       | Sentences        | Responses            |
| **Support Indicator**       | None               | Percentage         | Language         | Source               |
| **Provenance Indicator**    | None               | Trials             | Prompts            | Models             |
| **Modality**                | Text               | Sound              | Visualization      | Haptics            |

Use the figure component to display images, videos, equations, or any other element, with an optional caption.

If you stored your figures as PDFs, the `Picture` component can convert them into web-friendly images automatically.

<Figure>
  <Picture slot="figure" src="../assets/allstate-sparsity.pdf" alt="Impact of the sparsity-aware algorithm in XGBoost on the Allstate-10K dataset." invertInDarkMode />
  <Fragment slot="caption">Impact of the sparsity-aware algorithm in [XGBoost](https://arxiv.org/abs/1603.02754) on the Allstate-10K dataset.</Fragment>
</Figure>

Use the `Comparison` component to compare two elements with an interactive slider. It should work for any component or HTML element, including images, videos, and 3D models.


## Support Indicators

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left">
    <YouTubeVideo slot="figure" videoId="wjZofJX0v4M" />
    <Fragment slot="caption">Take a look at this YouTube video.</Fragment>
  </Figure>
  <Figure slot="right">
    <ModelViewer slot="figure" src="/BoxVertexColors.glb" alt="A cube colored with a rainbow gradient" />
    <Fragment slot="caption">Now look at this cube, rendered with the `<model-viewer>` web component.</Fragment>
  </Figure>
</TwoColumns>

## LaTeX

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="\int_a^b f(x) dx" />

## Results



## BibTeX 

```bibtex
@inproceedings{10.1145/3663547.3746393,
author = {Chen, Meng and Iyer, Akhil and Pavel, Amy},
title = {Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions},
year = {2025},
isbn = {9798400706769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663547.3746393},
doi = {10.1145/3663547.3746393},
abstract = {Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users’ ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado’s path to posting an image on social media.},
booktitle = {Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {66},
numpages = {17},
keywords = {Accessibility, Image Descriptions, Multimodal Large Language Models, Variations, AI Errors, Trust},
location = {Denver, CO, USA },
series = {ASSETS '25}
}
```