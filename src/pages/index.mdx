---
layout: ../layouts/Layout.astro
title: Surfacing Variations to Calibrate Perceived Reliability of MLLM-Generated Image Descriptions
authors:
  - name: Meng Chen
    url: https://meng-chen.com
    institution: UT Austin
  - name: Akhil Iyer
    institution: UT Austin
  - name: Amy Pavel
    url: https://amypavel.com
    institution: UC Berkeley
conference: ASSETS 2025
links:
  - name: Paper
    url: https://dl.acm.org/doi/full/10.1145/3663547.3746393
    icon: ri:file-pdf-2-line
  - name: Accessible PDF
    url: assets2025-surface-uncertainty.pdf
    icon: ri:file-pdf-2-line
  - name: arXiv
    url: https://arxiv.org/abs/2507.15692
    icon: academicons:arxiv
  - name: Code
    url: https://github.com/Casardo-Chen/surface-mllm-variations
    icon: ri:github-line
  - name: Demo
    url: #
    icon: ri:link

# The color theme of the page. Defaults to "device" (the preference set in the user's brower or operating system). Setting this to "light" or "dark" will override the user's preference. This is useful if your figures only look good in one theme.
theme: device

# This is the icon that appears in the user's browser tab. To customize, change the favicon.svg file in /public/, or add your own file to /public/ and change the filename here.
favicon: üå´Ô∏è

# These keys are optional. If a link to your project page is in a Google search result, text message, or social media post, it will often appear as a "link preview card" based on its title, description, favicon, and thumbnail. After you publish your page, you can double check that these previews look right using [this tool](https://linkpreview.xyz/)
description: Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions
thumbnail: ../assets/teaser.png
---

import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Picture from "../components/Picture.astro";
import ModelViewer from "../components/ModelViewer.astro"
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { Comparison } from "../components/Comparison.tsx";

import teaser from "../assets/teaser.png"
import preferences from "../assets/preferences.png"

import Table from "../components/Table.astro";
export const components = { table: Table }

<Figure>
  <Picture slot="figure" src={teaser} alt="Four labeled panels (A‚ÄìD) show how multiple MLLM outputs are aggregated into variation‚Äëaware descriptions. (A) Input photo of a home interior wall with framed art, a chair holding a laundry basket, and a small floral‚Äëcovered side table; prompt: Describe the room setting. Does this wall setting look okay? (B) Individual model descriptions (Gemini, GPT, Claude). (C) Hierarchical variation‚Äëaware Description groups cross‚Äëmodel observations: room is a living space (bedroom or den); walls soft green or gray textured; main furniture (bed or armchair or loveseat); other noted items (laundry basket on chair, small side table); wall decor pieces incl. larger artwork and red‚Äëflower print; subjective opinions split between cohesive/cozy vs cluttered. (D) Variation summary. Agreements (living space, small table, framed decor), Disagreements (main furniture type; decor cohesion), and Unique Mentions (GPT mentioned patterned fabric; Gemini mentioned hanging tassel; Claude mentioned traditional and vintage style)." invertInDarkMode />
  <Fragment slot="caption"> <b>(A)</b> Input image and prompt. <b>(B)</b> Raw image descriptions from 3 MLLMs (GPT-4o, Gemini-1.5-Pro, Claude-3.7-Sonnet).
<b>(C)</b> <i>Variation-Aware Description</i> aggregates all model outputs into a hierarchical markdown. Major variations are highlighted
in indigo. <b>(D)</b> <i>Variation summary</i> further surfaces key agreements, disagreements, and unique mentions across models.</Fragment>
</Figure>

<HighlightedSection>

## Abstract

Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users‚Äô ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado‚Äôs path to posting an image on social media.

</HighlightedSection>

## Design and Pipeline

| **Dimension**              | **Alternatives** | | | |
|-----------------------------|--------------------|--------------------|--------------------|--------------------|
| **Elicitation of Variants** | `Trials`             |  `Prompts`           |  `Models`            | Images             |
| **Comparison Support**      | `List`               | `Variation-aware description` | `Variation Summary` |            |
| **Comparison Granularity**  | Words              | `Atomic facts`       | Sentences        | `Responses`            |
| **Support Indicator**       | `None`               | `Percentage`         | `Language`         | `Source`               |
| **Provenance Indicator**    | None               | Trials             | Prompts            | `Models`             |
| **Modality**                | `Text`               | Sound              | Visualization      | Haptics            |

Design space for surfacing MLLM variations. `Alternatives` marked with backticks indicate the choices implemented in our prototype system. 

We elicit variants by running multiple **trials** (repeated queries), using different **prompts**, and querying multiple **models**. We then compare MLLM-generated descriptions at the granularity of **atomic facts** (individual descriptive claims) and present variations using a **list** format, a **variation-aware description**, and a separate **variation summary**. 

## Support Indicators

We provide three support indicators (**language**, **percentage**, and **source**) to show how many of each model agree with each claim.

| **None** | **Language** | **Percentage** | **Source** |
|-----------|--------------|----------------|-------------|
| There are two <span style="background-color:#ccffcc;">white chairs</span> on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble or glass or wood</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books and a television</span>. | There are two <span style="background-color:#ccffcc;">white (well-supported)</span> chairs on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble (moderately supported) or glass (poorly supported) or wood (very little support)</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books (moderately supported) and a television (moderately supported)</span>. | There are two <span style="background-color:#ccffcc;">white (100%)</span> chairs on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble (56%) or glass (33%) or wood (11%)</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books (33%) and a television (33%)</span>. | There are two <span style="background-color:#ccffcc;">white (3 of 3 GPT, 3 of 3 Gemini, 3 of 3 Claude)</span> chairs on the left and a grey sofa on the right. At the center there is a white coffee table with a <span style="background-color:#ffcccc;">marble (3 of 3 GPT, 2 of 3 Gemini) or glass (3 of 3 Claude) or wood (1 of 3 Gemini)</span> top and a gold base. There is a built-in shelf on the back wall with decorative items, like <span style="background-color:#cce5ff;">books (3 of 3 GPT) and a television (3 of 3 Gemini)</span>. |

Variation-aware description without support indicator and with three variant support indicators (Language, Percentage, Source). Agreements (top, <span style="background-color:#ccffcc;">green</span>), disagreements (middle, <span style="background-color:#ffcccc;">red</span>), and unique mentions (bottom, <span style="background-color:#cce5ff;">blue</span>) are highlighted.


## Results

**Surfacing variations in MLLM responses significantly increased the number of unreliable claims identified** by 4.9x for **ours** or 4.2x for **list** compared to presenting a **single** description. **Variations also significantly decreased the perceived reliability of MLLM responses** from 5.78 of 7 for a single description to 4.76 for a list of descriptions and 3.93 for ours. 

<Figure>
  <Picture slot="figure" src="../assets/results_bars.pdf" alt="Two bar charts compare three presentation styles‚ÄîSingle (red), List (yellow), and Ours (blue)‚Äîon two metrics: the number of identified unreliable claims (left) and perceived reliability (right). The left chart shows that Ours led to significantly more unreliable claims being identified across all categories (Overall, Model Limitation, Image Quality, and Subjectivity). The right chart shows Single descriptions were rated highest in perceived reliability, followed by List, with Ours rated lowest in several categories. Statistical significance is indicated with asterisks (* p < 0.05, ** p < 0.01, *** p < 0.001)." invertInDarkMode />
  <Fragment slot="caption"> <b>Left:</b> average identified unreliable claims reported by participants overall and in each image category. <br /> <b>Right:</b> average perceived reliability rating (1 = not reliable at all, 7 = most reliable) overall and in each image category. <br />
  Error bars represent a 95\% confidence interval. We applied the Friedman test followed by pairwise Wilcoxon signed-rank tests with Bonferroni correction. Significance is marked as * p < 0.05, ** p < 0.01, and *** p < 0.001.</Fragment>
</Figure>

11 of 15 participants ranked our **variation summary (ours)** as their favorite option with 9 of 15 ranking it as their second favorite, while only 5 participants rated the list or single description as their first or second favorite, indicating strong support for our aggregated variation approaches. 

<Figure>
  <Picture slot="figure" src={preferences} alt="Two horizontal stacked bar charts. Left: titled Preference for Presentation Style compares user rankings (1 = most preferred, 4 = least preferred) across four styles: Variation Summary, Variation-Aware Description, List of Multiple Descriptions, and Single Description. Variation Summary received the most Rank 1 votes (11), followed by Variation-Aware Description (9). Single Description received the most Rank 4 votes (7), indicating it was the least preferred overall. Each bar is color-coded by rank. Right: titled Preference for Support Indicator compares user rankings (1 = most preferred, 4 = least preferred) for four styles: Source, Percentage, None, and Language. Source received the most Rank 1 and Rank 2 votes combined (5 and 7), indicating a strong preference. Language received the most Rank 4 votes (7), making it the least preferred overall. Each bar is divided into four color-coded segments representing ranks 1 through 4." invertInDarkMode />
  <Fragment slot="caption"> <b>Left:</b> Participants' preference for variation presentation style and single description. <br/> <b>Right:</b>  Participants‚Äô preference for support indicators <br/> (1 = most preferred, 4 = least preferred)</Fragment>
</Figure>

All BLV participants wanted to use our variation surfacing prototype in the future for a variety of purposes from **high-stakes scenarios** such as assessing the path of an incoming tornado to **obtaining subjective critiques** for social media posts.

## BibTeX 

```bibtex
@inproceedings{10.1145/3663547.3746393,
  author = {Chen, Meng and Iyer, Akhil and Pavel, Amy},
  title = {Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions},
  year = {2025},
  isbn = {9798400706769},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3663547.3746393},
  doi = {10.1145/3663547.3746393},
  abstract = {Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users‚Äô ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado‚Äôs path to posting an image on social media.},
  booktitle = {Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility},
  articleno = {66},
  numpages = {17},
  keywords = {Accessibility, Image Descriptions, Multimodal Large Language Models, Variations, AI Errors, Trust},
  location = {Denver, CO, USA },
  series = {ASSETS '25}
}
```

#### Acknowledgments

This work was supported in part by a <a href="https://ethics.nd.edu/labs-and-centers/notre-dame-ibm-technology-ethics-lab/research-grants/">Notre Dame-IBM Technology Ethics Lab</a> Award. 